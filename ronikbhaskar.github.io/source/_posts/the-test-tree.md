---
title: The Test Tree
description: >-
I think, to some extent, we are all afraid of tech companies stealing our data. It's most evident when we're talking about something, like needing a new coffee table, and suddenly our feeds are covered in ads for coffee tables. This fear manifests itself in other ways too, from facial recognition working a bit too well to AIs that seem to have read the entire internet. It's a justified fear. Data theft and data abuse pose real, personal risks to almost everyone. For me, however, data theft is not just a personal risk; it's an occupational hazard.
keywords: test tree, stealing data, testing AI, research narrative, occupational hazard
date: 2024-04-15 15:32:49
tags:
---

<img src="/images/test_tree.png" alt="Test Tree, by Ronik Bhaskar.">

---

I think, to some extent, we are all afraid of tech companies stealing our data. It's most evident when we're talking about something, like needing a new coffee table, and suddenly our feeds are covered in ads for coffee tables. This fear manifests itself in other ways too, from facial recognition working a bit too well to AIs that seem to have read the entire internet. It's a justified fear. Data theft and data abuse pose real, personal risks to almost everyone. For me, however, data theft is not just a personal risk; it's an occupational hazard.

In my work, I spend a lot of time testing AI or AI-related tools. Most of the time, those tools are internal, like [Glaze](https://glaze.cs.uchicago.edu/webglaze.html), so I don't have to worry about my data being misused. In a recent [project](https://arxiv.org/abs/2402.03214), though, I had to test commercial products, and I had no control over how my data was used. 

Early in the project, as I was doing some initial experiments, I realized I didn't have any images I could safely feed AI. They were all photos of either people or places in my life, and those seemed a bit too personal. So, I pulled out my phone and used my finger to draw a quick tree. It took about two minutes, and it didn't look very good, but I had no attachment to it, and I was more than happy to feed it to some monstrous training datasets. 

And so, I did. I ran countless experiments with that tree, testing different tools and making strange modifications. I even began using it when privacy wasn't a concern. It has become an inside joke with people in the lab just how much I use that tree. Honestly, I can't help it. That tree has worked with me through long nights and intense debugging sessions. It's gone through every experimental pipeline I've built. My work would not be the same without it.

The unfortunate reality is that this tree, with so much personal value, is now sitting in some massive training datasets, waiting to be misused by tech companies. All that testing has finally caught up with me. I tried not to use personal data when testing these tools, but the data I was using became personal. And now, it's not just gone. It's everywhere. Any tech company that has ever touched this image has full access to it.

Ultimately, I think this is for the best. The important thing was never the tree being secret. Its presence everywhere means the protection of so many images that could have taken it's place. Its purpose is to be stolen, to be used, to be a waste of space in a sea of sensitive data. In that way, it was never mine to begin with. It's meant for everyone, and if you're looking for your own test image, maybe it can be yours too.